{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39727d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.1 environment at: dev3\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m13 packages\u001b[0m \u001b[2min 501ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/13.06 KiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/13.06 KiB           \u001b[1A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/14.21 KiB           \u001b[2A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/14.21 KiB           \u001b[2A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/14.21 KiB           \u001b[2A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.21 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/157.44 KiB          \u001b[3A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.21 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/157.44 KiB          \u001b[3A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.21 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/157.44 KiB          \u001b[3A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.21 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/157.44 KiB          \u001b[3A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mannotated-types     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.32 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.21 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/157.44 KiB          \u001b[4A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mannotated-types     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.32 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.21 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/157.44 KiB          \u001b[4A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mannotated-types     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.32 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.21 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/157.44 KiB          \u001b[4A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mannotated-types     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.32 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.21 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/157.44 KiB          \u001b[4A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mannotated-types     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.32 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.21 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/157.44 KiB          \u001b[4A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mannotated-types     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.32 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.21 KiB\n",
      "\u001b[2mcertifi             \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/157.44 KiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/434.36 KiB          \u001b[5A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mannotated-types     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.32 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 14.21 KiB/14.21 KiB\n",
      "\u001b[2mcertifi             \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/157.44 KiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/434.36 KiB          \u001b[5A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.06 KiB\n",
      "\u001b[2mannotated-types     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.32 KiB\n",
      "\u001b[2mtyping-inspection   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 14.21 KiB/14.21 KiB\n",
      "\u001b[2mcertifi             \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/157.44 KiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m     0 B/434.36 KiB          \u001b[5A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 13.06 KiB/13.06 KiB\n",
      "\u001b[2mannotated-types     \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 13.32 KiB/13.32 KiB\n",
      "\u001b[2mcertifi             \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/157.44 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m 14.88 KiB/434.36 KiB        \u001b[4A\n",
      "\u001b[2mollama              \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 13.06 KiB/13.06 KiB\n",
      "\u001b[2manyio               \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.89 KiB/104.70 KiB\n",
      "\u001b[2mcertifi             \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 46.88 KiB/157.44 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m 14.88 KiB/434.36 KiB        \u001b[4A\n",
      "\u001b[2manyio               \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.89 KiB/104.70 KiB\n",
      "\u001b[2mcertifi             \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 157.44 KiB/157.44 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 46.88 KiB/434.36 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m 14.91 KiB/1.91 MiB          \u001b[4A\n",
      "\u001b[2manyio               \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 46.89 KiB/104.70 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 62.88 KiB/434.36 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------\u001b[2m--\u001b[0m\u001b[0m 1.75 MiB/1.91 MiB           \u001b[3A\n",
      "\u001b[2manyio               \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 62.89 KiB/104.70 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)--------------\u001b[0m\u001b[0m 124.40 KiB/434.36 KiB       \u001b[2A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m7 packages\u001b[0m \u001b[2min 42ms\u001b[0m\u001b[0m                                                  \u001b[1A\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/12] \u001b[2mInstalling wheels...                                \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m12 packages\u001b[0m \u001b[2min 825ms\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mollama\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb550f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LML) refers to an artificial intelligence system that processes and outputs text data with millions of words. LMs can be used for various tasks such as natural language processing, language translation, sentiment analysis, and predictive modeling in natural language processing (NLP). They are designed to mimic human-like reasoning capabilities by analyzing vast amounts of text data, identifying patterns, and making predictions about future outcomes based on past behavior.\n",
      "\n",
      "LMLs can be categorized into several types:\n",
      "\n",
      "1. **Natural Language Processing (NLP)**: LMs that use a neural network or machine learning algorithms to process and understand human language, such as chatbots, voice assistants, and language translation software.\n",
      "2. **Language Modeling**: LMS based on machine learning techniques to generate text output, including speech recognition, transcription, and question answering tasks in natural language processing (NLP).\n",
      "3. **Synthetic Language Generation**: A type of LML that generates synthetic text using a combination of statistical and neural algorithms for various applications like product reviews, news articles, marketing campaigns, and customer service interactions.\n",
      "4. **Pattern Recognition**: LMS based on pattern recognition techniques to identify specific characteristics in text data such as keywords, words, phrases, sentences, or even entire paragraphs and classify them into different categories, similar concepts, or patterns that can be used for machine learning tasks like language translation and sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "response = chat(model='smollm2:135m', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'what is a large language model?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a94e9840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LML) refers to an artificial intelligence system that processes and outputs text data with millions of words. LMs can be used for various tasks such as natural language processing, language translation, sentiment analysis, and predictive modeling in natural language processing (NLP). They are designed to mimic human-like reasoning capabilities by analyzing vast amounts of text data, identifying patterns, and making predictions about future outcomes based on past behavior.\n",
      "\n",
      "LMLs can be categorized into several types:\n",
      "\n",
      "1. **Natural Language Processing (NLP)**: LMs that use a neural network or machine learning algorithms to process and understand human language, such as chatbots, voice assistants, and language translation software.\n",
      "2. **Language Modeling**: LMS based on machine learning techniques to generate text output, including speech recognition, transcription, and question answering tasks in natural language processing (NLP).\n",
      "3. **Synthetic Language Generation**: A type of LML that generates synthetic text using a combination of statistical and neural algorithms for various applications like product reviews, news articles, marketing campaigns, and customer service interactions.\n",
      "4. **Pattern Recognition**: LMS based on pattern recognition techniques to identify specific characteristics in text data such as keywords, words, phrases, sentences, or even entire paragraphs and classify them into different categories, similar concepts, or patterns that can be used for machine learning tasks like language translation and sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb1f8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A large language model (LML) refers to an artificial intelligence system that processes and outputs text data with millions of words. LMs can be used for various tasks such as natural language processing, language translation, sentiment analysis, and predictive modeling in natural language processing (NLP). They are designed to mimic human-like reasoning capabilities by analyzing vast amounts of text data, identifying patterns, and making predictions about future outcomes based on past behavior.\n",
       "\n",
       "LMLs can be categorized into several types:\n",
       "\n",
       "1. **Natural Language Processing (NLP)**: LMs that use a neural network or machine learning algorithms to process and understand human language, such as chatbots, voice assistants, and language translation software.\n",
       "2. **Language Modeling**: LMS based on machine learning techniques to generate text output, including speech recognition, transcription, and question answering tasks in natural language processing (NLP).\n",
       "3. **Synthetic Language Generation**: A type of LML that generates synthetic text using a combination of statistical and neural algorithms for various applications like product reviews, news articles, marketing campaigns, and customer service interactions.\n",
       "4. **Pattern Recognition**: LMS based on pattern recognition techniques to identify specific characteristics in text data such as keywords, words, phrases, sentences, or even entire paragraphs and classify them into different categories, similar concepts, or patterns that can be used for machine learning tasks like language translation and sentiment analysis."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db15815f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A large language model (LML) is a computer program that uses natural language processing (NLP), machine learning algorithms to generate text responses or queries based on pre-defined rules and constraints. It typically involves multiple layers of processing, including:\n",
       "\n",
       "1. **Model Training**: The LML is trained using a corpus of texts, which contains examples from various domains such as literature, science, technology, medicine, social sciences, arts, entertainment, education, marketing, etc., to develop the model's understanding and capability in generating accurate responses.\n",
       "2. **NLP**: The NLP component analyzes the text data provided by the LML, identifies patterns and relationships between words, phrases, and sentences, and generates a set of linguistic representations that can be used for various applications, such as question answering, sentiment analysis, content generation, or machine translation.\n",
       "3. **Query Processing**: The model processes the NLP inputs to generate a response based on specific queries (queries), which are presented in text form by the LML's backend system.\n",
       "4. **Evaluation and Testing**: The LML is evaluated using various metrics such as accuracy, precision, recall, F1-score, etc., depending on the nature of the responses provided by the LML.\n",
       "5. **Integration with Other Applications**: Some models can integrate directly with other applications, such as:\n",
       "\n",
       "1. **Web crawlers** and API scraping for accessing real-world content in various domains (e.g., databases, web sites).\n",
       "2. **Machine translation systems**, which enable users to translate text from one language to another.\n",
       "3. **Speech recognition tools**, which can transcribe spoken words into written texts or speech.\n",
       "4. **Content recommendation engines** and services like Amazon's Alexa, Google Assistant, and Apple's Siri that generate personalized content based on user preferences (e.g., recommendations for movies, music).\n",
       "6. **Automation**: Some models are used in automated systems to perform tasks such as book finding, answering queries, or generating reports (e.g., customer support, finance)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "model = 'smollm2:135m'\n",
    "\n",
    "response = chat(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistance. Your answers are always short, and in bullet points.'},\n",
    "        {'role': 'user', 'content': 'what is a large language model?'}],\n",
    ")\n",
    "Markdown(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27a7e5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LML) is an artificial intelligence system that mimics the human ability to learn and adapt through experience. It can process vast amounts of text data from various sources, like books, articles, online platforms, social media, and more. The LML's capabilities include:\n",
      "\n",
      "1. Natural Language Processing (NLP): It analyzes large amounts of text to understand language patterns, grammar rules, and word meanings.\n",
      "2. Machine Learning: It uses algorithms to learn from large datasets and adapt its responses based on what it has learned.\n",
      "3. Knowledge Representation: The LML can represent complex concepts and decisions in a way that makes them easy for humans to understand.\n",
      "4. Corpus Analysis: It analyzes vast amounts of text data, including language, culture, history, and more, to extract insights and meaning.\n",
      "5. Chatbots: A LML is often used as a conversational assistant by businesses or organizations to provide information, answer questions, or facilitate communication with customers.\n",
      "6. Language Translation: Some LMs can translate languages for non-native speakers and assist international visitors with travel queries and language difficulties.\n",
      "7. Sentiment Analysis: It analyzes written text to identify emotions expressed by characters in a conversation.\n",
      "8. Knowledge Graphs: A LML creates a vast collection of knowledge graphs that contain information about various topics, allowing it to understand relationships between entities and make informed decisions.\n",
      "9. Speech Recognition: The LML can recognize spoken words or texts using speech recognition technology, enabling voice-based interfaces for text-based applications like chatbots, online services, and mobile apps.\n",
      "10. Predictive Modeling: The LML uses machine learning algorithms to forecast future events, track user behavior, and anticipate responses from users.\n",
      "\n",
      "LMLs are used in various industries, including e-commerce, customer service, marketing, healthcare, finance, education, and more due to their ability to handle vast amounts of text data efficiently and effectively."
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "model = 'smollm2:135m'\n",
    "\n",
    "stream = chat(\n",
    "    model=model,\n",
    "    messages=[{'role': 'user', 'content': 'what is a large language model?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb280bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "\n",
    "\n",
    "def generate_email(subject, recipient_name, additional_info):\n",
    "    \n",
    "    prompt = f\"Write a professional email to {recipient_name} with the subject '{subject}'. Include the following information: {additional_info}\"\n",
    "    \n",
    "    response = chat(\n",
    "        model=\"smollm2:135m\",  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ])\n",
    "    return response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06aa408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_writing_assistant():\n",
    "    print(\"Welcome to the Email Writing Assistant!\\n\")\n",
    "    \n",
    "    # Step 4: Gather user input for the email subject, recipient name, and additional information\n",
    "    subject = input(\"Enter the email subject: \")\n",
    "    recipient_name = input(\"Enter the recipient's name: \")\n",
    "    additional_info = input(\"Enter any additional information to include in the email: \")\n",
    "    \n",
    "    # Step 5: Call the 'generate_email' function and display the generated email\n",
    "    email = generate_email(subject, recipient_name, additional_info)\n",
    "    print(f\"Email:\\n{email}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8573cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Email Writing Assistant!\n",
      "\n",
      "Email:\n",
      "Subject: PTO Team Sendout Request\n",
      "\n",
      "Dear [Sara's Name],\n",
      "\n",
      "We wanted to send out a professional email to you regarding your upcoming performance review. We are writing for you because we believe this is an essential meeting with you, as it will be crucial that we communicate our progress and provide valuable insights based on the information shared during the previous review session.\n",
      "\n",
      "In preparation for this important call, we have reviewed the current performance metrics, objectives, and expectations outlined in our last two reviews. We understand your commitment to excellence and are eager to ensure a positive outcome for you.\n",
      "\n",
      "Please feel free to reach out with any questions or concerns at your earliest convenience. Your feedback will be invaluable as we move forward and work together to achieve your goals. If there is anything specific that requires immediate attention, please let us know by sharing it in our email.\n",
      "\n",
      "Thank you again for considering our review team for this important meeting. We look forward to working with you and making the most of this opportunity.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "PTSO Team\n"
     ]
    }
   ],
   "source": [
    "email_writing_assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808d360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
